---
title: 'Lab 3: Panel Models'
subtitle: 'US Traffic Fatalities: 1980 - 2004'
output: 'pdf_document'
---

```{r load packages, echo=FALSE, message=FALSE}
if(!"plm"%in%rownames(installed.packages())) {install.packages("plm")} 
library(plm) 
if(!"plyr"%in%rownames(installed.packages())) {install.packages("plyr")} 
library(plyr) 
if(!"dplyr"%in%rownames(installed.packages())) {install.packages("dplyr")} 
library (dplyr) 
if(!"ggplot2"%in%rownames(installed.packages())) {install.packages("ggplot2")} 
library(ggplot2) 
if(!"ggthemes"%in%rownames(installed.packages())) {install.packages("ggthemes")} 
library(ggthemes) 
if(!"scales"%in%rownames(installed.packages())) {install.packages("scales")} 
library (scales) 
if(!"reshape2"%in%rownames(installed.packages())) {install.packages("reshape2")} 
library(reshape2) 
if(!"gridExtra"%in%rownames(installed.packages())) {install.packages("gridExtra")} 
library(gridExtra) 
if(!"lubridate"%in%rownames(installed.packages())) {install.packages("lubridate")} 
library (lubridate) 
if(!"stargazer "%in%rownames(installed.packages())) {install.packages("stargazer")} 
library(stargazer) 
if(!"mgcv"%in%rownames(installed.packages())) {install.packages("mgcv")} 
library(mgcv) 
if(!"knitr"%in%rownames(installed.packages())) {install.packages("knitr")} 
library(knitr) 
if(!"tidyverse"%in%rownames(installed.packages())) {install.packages("tidyverse")} 
library(tidyverse) 
if(!"patchwork"%in%rownames(installed.packages())) {install.packages("patchwork")} 
library(patchwork)
if(!"fredr"%in%rownames(installed.packages())) {install.packages("fredr")} 
library(fredr)
if(!"tsibble"%in%rownames(installed.packages())) {install.packages("tsibble")} 
library(tsibble)
if(!"tseries"%in%rownames(installed.packages())) {install.packages("tseries")} 
library(tseries)
if(!"feasts"%in%rownames(installed.packages())) {install.packages("feasts")} 
library(feasts)
if(!"scales"%in%rownames(installed.packages())) {install.packages("scales")} 
library(scales)
if(!"lmtest"%in%rownames(installed.packages())) {install.packages("lmtest")} 
library(lmtest)
```

# U.S. traffic fatalities: 1980-2004

In this lab, we are asking you to answer the following **causal** question: 

> **"Do changes in traffic laws affect traffic fatalities?"**  

To answer this question, please complete the tasks specified below using the data provided in `data/driving.Rdata`. This data includes 25 years of data that cover changes in various state drunk driving, seat belt, and speed limit laws. 

Specifically, this data set contains data for the 48 continental U.S. states from 1980 through 2004. Various driving laws are indicated in the data set, such as the alcohol level at which drivers are considered legally intoxicated. There are also indicators for “per se” laws—where licenses can be revoked without a trial—and seat belt laws. A few economics and demographic variables are also included. The description of the each of the variables in the dataset is also provided in the dataset. 

```{r load data, echo = TRUE}
load(file="./data/driving.RData")

## please comment these calls in your work 
head(data)
desc
```
# (30 points, total) Build and Describe the Data 

1. (5 points) Load the data and produce useful features. Specifically: 
    - Produce a new variable, called `speed_limit` that re-encodes the data that is in `sl55`, `sl65`, `sl70`, `sl75`, and `slnone`; 
    - Produce a new variable, called `year_of_observation` that re-encodes the data that is in `d80`, `d81`, ... , `d04`. 
    - Produce a new variable for each of the other variables that are one-hot encoded (i.e. `bac*` variable series). 
    - Rename these variables to sensible names that are legible to a reader of your analysis. For example, the dependent variable as provided is called, `totfatrte`. Pick something more sensible, like, `total_fatalities_rate`. There are few enough of these variables to change, that you should change them for all the variables in the data. (You will thank yourself later.)
2. (5 points) Provide a description of the basic structure of the dataset. What is this data? How, where, and when is it collected? Is the data generated through a survey or some other method? Is the data that is presented a sample from the population, or is it a *census* that represents the entire population? Minimally, this should include:
    - How is the our dependent variable of interest `total_fatalities_rate` defined? 
3. (20 points) Conduct a very thorough EDA, which should include both graphical and tabular techniques, on the dataset, including both the dependent variable `total_fatalities_rate` and the potential explanatory variables. Minimally, this should include: 
    - How is the our dependent variable of interest `total_fatalities_rate` defined? 
    - What is the average of `total_fatalities_rate` in each of the years in the time period covered in this dataset? 

As with every EDA this semester, the goal of this EDA is not to document your own process of discovery -- save that for an exploration notebook -- but instead it is to bring a reader that is new to the data to a full understanding of the important features of your data as quickly as possible. In order to do this, your EDA should include a detailed, orderly narrative description of what you want your reader to know. Do not include any output -- tables, plots, or statistics -- that you do not intend to write about.

```{r}
#head(data)
```

```{r Load the data and produce useful features}
#speed limit 
data$speed_limit <- with(data, 
  ifelse(as.integer(sl55 >= 0.5), 55,
    ifelse(as.integer(sl65 >= 0.5), 65,
      ifelse(as.integer(sl70 >= 0.5), 70,
        ifelse(as.integer(sl75 >= 0.5), 75, 
          ifelse(as.integer(slnone >= 0.5), NA, NA))))))

#year of observation
year_vars <- grep("^d\\d{2}$", names(data), value = TRUE)
data$year_of_observation <- apply(data[, year_vars], 1, function(x) 1980 + which(x == 1) - 1)

#data <- data[, !(names(data) %in% c(year_vars, "sl55", "sl65", "sl70", "sl75", "slnone"))]
data <- data[, !(names(data) %in% c("sl55", "sl65", "sl70", "sl75", "slnone"))]

#make sure they are indicating 0 and 1 respectively 
data$bac10 <- round(data$bac10)
data$bac08<- round(data$bac08)
data$sbprim <- round(data$sbprim)
data$sbsecon <- round(data$sbsecon)

data$minage <- round(data$minage)
data$perse <- round(data$perse)
data$zerotol <- round(data$zerotol)
data$gdl <- round(data$gdl)
data$sl70plus <- round(data$sl70plus)

#rename for clarity 
names(data)[names(data) == "totfatpvm"] <- "total_fatalities_pvm"
names(data)[names(data) == "nghtfatpvm"] <- "night_fatalities_pvm"
names(data)[names(data) == "wkndfatpvm"] <- "weekend_fatalities_pvm"
names(data)[names(data) == "totfatrte"] <- "total_fatalities_rate"
names(data)[names(data) == "nghtfatrte"] <- "night_fatalities_rate"
names(data)[names(data) == "wkndfatrte"] <- "weekend_fatalities_rate"
names(data)[names(data) == "unem"] <- "unemployment_rate"

names(data)[names(data) == "gdl"] <- "graduated_drivers_license_law"
names(data)[names(data) == "zerotol"] <- "zero_tolerance_law"
names(data)[names(data) == "totfat"] <- "total_fatalities"
names(data)[names(data) == "nghtfat"] <- "total_nighttime_fatalities"
names(data)[names(data) == "wkndfat"] <- "total_weekend_fatalities"
names(data)[names(data) == "sbprim"] <- "primary_seatbelt_law"
names(data)[names(data) == "sbsecon"] <- "secondary_seatbelt_law"

```

```{r, rename states}
data$state[data$state == 1] <- 'al'
data$state[data$state == 3] <- 'az'
data$state[data$state == 4] <- 'ar'
data$state[data$state == 5] <- 'ca'
data$state[data$state == 6] <- 'co'
data$state[data$state == 7] <- 'ct'
data$state[data$state == 8] <- 'de'
data$state[data$state == 10] <- 'fl'
data$state[data$state == 11] <- 'ga'
data$state[data$state == 13] <- 'id'
data$state[data$state == 14] <- 'il'
data$state[data$state == 15] <- 'in'
data$state[data$state == 16] <- 'ia'
data$state[data$state == 17] <- 'ks'
data$state[data$state == 18] <- 'ky'

data$state[data$state == 19] <- 'la'
data$state[data$state == 20] <- 'me'
data$state[data$state == 21] <- 'md'
data$state[data$state == 22] <- 'ma'
data$state[data$state == 23] <- 'mi'
data$state[data$state == 24] <- 'mn'
data$state[data$state == 25] <- 'ms'
data$state[data$state == 26] <- 'mo'
data$state[data$state == 27] <- 'mt'
data$state[data$state == 28] <- 'ne'
data$state[data$state == 29] <- 'nv'
data$state[data$state == 30] <- 'nh'
data$state[data$state == 31] <- 'nj'


data$state[data$state == 32] <- 'nm'
data$state[data$state == 33] <- 'ny'
data$state[data$state == 34] <- 'nc'
data$state[data$state == 35] <- 'nd'
data$state[data$state == 36] <- 'oh'
data$state[data$state == 37] <- 'ok'
data$state[data$state == 38] <- 'or'
data$state[data$state == 39] <- 'pa'
data$state[data$state == 40] <- 'ri'
data$state[data$state == 41] <- 'sc'


data$state[data$state == 42] <- 'sd'
data$state[data$state == 43] <- 'tn'
data$state[data$state == 44] <- 'tx'
data$state[data$state == 45] <- 'ut'
data$state[data$state == 46] <- 'vt'
data$state[data$state == 47] <- 'va'
data$state[data$state == 48] <- 'wa'
data$state[data$state == 49] <- 'wv'
data$state[data$state == 50] <- 'wi'
data$state[data$state == 51] <- 'wy'



```


The traffic fatalities data originates from the Fatality Analysis Reporting System (FARS), managed by the National Highway Traffic Safety Administration (NHTSA). This system gathers data on every traffic crash across the 48 contiguous United States that results in the death of a vehicle occupant or a nonmotorist. The data collection process, conducted by state employees, employs a standardized format to ensure consistency and comparability across different states.

The dependent variable of interest, total_fatalities_rate, is defined as the number of traffic fatalities per 100,000 population at the state level over over the years 1980-2004. The dataset consists of approximately 1200 records, reflecting 48 records for each of the 25 years covered.

The independent variables include indicator variables for control legislation, including blood alcohol limit, graduated drivers license law, seat belt, and speed limit laws. Other controls include continuous variables for mileage traveled and demographic characteristics.

This dataset represents a census of traffic fatalities, rather than a sample. It documents every recorded instance of traffic-related fatalities within its scope and time frame, making it a complete record for the study period and not a subset of the total incidents. 


```{r}
average_fatalities_per_year <- aggregate(total_fatalities_rate ~ year_of_observation, data, mean)

ggplot(average_fatalities_per_year, aes(x = year_of_observation, y = total_fatalities_rate)) +
    geom_line() +
    labs(title = "Average Total Fatalities Rate per Year",
         x = "Year",
         y = "Average Total Fatalities Rate") +
    theme_minimal()
```
The graph shows a significant downward trend in the average total fatalities rate per year from 1980 to 2004. From the early 1990s onwards, the rate shows some fluctuations but generally remains at a lower rate than at the start of the period observed. This suggests that road safety may have improved, possibly due to policy changes, improved vehicle safety, or other factors.

```{r}
average_by_age <- aggregate(total_fatalities_rate ~ minage, data = data, FUN = mean)
#print(average_by_age)
```

Table 1: Average Total Fatalities by Minimum Drinking Age 

| Minimum Drinking Age          | 18    | 19    | 20    | 21    | 
|:-----------------------------:|------:|------:|------:|-------:
| Average Total Fatalities Rate | 23.96 | 21.33 | 19.76 | 18.20 |

This table suggests that as the minimum legal drinking age increases, the average total fatalities rate decreases. This trend may imply that higher drinking age laws could be contributing to improved road safety, possibly by reducing alcohol consumption among younger drivers. 

```{r,fig.width = 10,fig.height=4, warning=FALSE}

p1_bar <- ggplot(data, aes(x=factor(seatbelt), y=total_fatalities_rate, fill=factor(seatbelt))) +
  geom_bar(stat="summary", fun=mean) +
  labs(title="Average Total Fatalities by Seat Belt Law",x="Seatbelt Law", y="Average Total Fatalities Rate", fill="Seatbelt Law") + 
  theme_minimal() +
  scale_fill_brewer(palette="Set1", labels=c("No Law", "Primary Law", "Secondary Law")) +
  scale_x_discrete(labels=c("No Law", "Primary Law", "Secondary Law")) 


p2_bar <- ggplot(data, aes(x=factor(sl70plus), y=total_fatalities_rate, fill=factor(sl70plus))) +
  geom_bar(stat="summary", fun=mean) +
  labs(title="Average Total Fatalities by Speed Limit", x="Speed Limit (MPH)", y="Average Total Fatalities Rate", fill="Speed Limit") +
  theme_minimal() +
  scale_fill_brewer(palette="Set2",labels=c("0"="Less than 70 MPH", "1"="Over 70 MPH")) +
  scale_x_discrete(labels=c("0"="Less than 70 MPH", "1"="Over 70 MPH")) +
  scale_fill_discrete(labels=c("0"="Less than 70 MPH", "1"="Over 70 MPH"))
p1_bar | p2_bar
```

The seat belt law graph shows that regions with no seatbelt law (0) have the highest average fatality rate, while those with a primary enforcement law (1) show a lower rate, and secondary enforcement (2) has the lowest. This indicates that stricter seatbelt laws could be associated with reduced fatalities. The speed limit graph shows that when the speed limit is over 70 the average total fatalities rate is a bit higher, but interestingly not by much. 

```{r, fig.width = 10,fig.height=4}
p1_box <- ggplot(data, aes(x=factor(graduated_drivers_license_law), y=total_fatalities_rate)) +
  geom_boxplot() +
  labs(title="Average Total Fatalities by GDL",
       x="Graduated Drivers License Law", 
       y="Average Total Fatalities Rate") +
  theme_minimal()

p2_box <- ggplot(data, aes(x=factor(zero_tolerance_law), y=total_fatalities_rate)) +
  geom_boxplot() +
  labs(title="Average Total Fatalities by Zero Tolerance Law",
       x="Zero Tolerance Law", 
       y="Average Total Fatalities Rate") +
  theme_minimal()

p1_box | p2_box
```
The box plots comparing average total fatalities rates against the presence of Graduated Drivers License Law and Zero Tolerance Law show a lower median fatality rate when these laws are in place (indicated by '1') as opposed to when they are not (indicated by '0'). 
```{r,fig.width = 10,fig.height=4, warning=FALSE}
data |> 
  ggplot(aes(reorder(state,desc(total_fatalities_rate)), total_fatalities_rate, fill=state))+
  geom_boxplot(alpha=0.4) +
  theme_economist_white(gray_bg=F)+
  theme(legend.position = "none", axis.text.y = element_text(size=6)) + 
  scale_y_continuous(label=scales::number_format(accuracy = 1))+
  xlab("State")+
  ylab("Total fatalities per 100k population")+
  coord_flip()
```
We see strong differences in fatality rate across different states over time, suggesting that fixed effects are important for controlling for unobserved differences.

```{r,fig.width = 10,fig.height=4, warning=FALSE}
data |> 
  ggplot(aes(year_of_observation, total_fatalities_rate, color = state))+
  geom_point(alpha=0.4) +
  geom_smooth(method="lm") +
  facet_wrap(~state) +
  theme_economist_white(gray_bg=F)+
  theme(legend.position = "none", axis.text.x=element_text(angle=45,hjust=1,vjust=1,size=8),
        axis.text.y = element_text(size=8)) + 
  theme(strip.text = element_text(size=4)) +
  scale_y_continuous(label=scales::number_format(accuracy = 1))+
  xlab("State")+
  ylab("Total fatalities per 100k population")

```
We see that fatality rate appear to have been trending down in most state over time, with some being more flat.

```{r numeric vars}
summary(data$perc14_24)
summary(data$unemployment_rate)
summary(data$vehicmilespc)
```
The scale of vehicle miles driven per capita is far larger than the percentage and rate variables. 

# (15 points) Preliminary Model

Estimate a linear regression model of *totfatrte* on a set of dummy variables for the years 1981 through 2004 and interpret what you observe. In this section, you should address the following tasks: 

- Why is fitting a linear model a sensible starting place? 
- What does this model explain, and what do you find in this model? 
- Did driving become safer over this period? Please provide a detailed explanation.
- What, if any, are the limitation of this model. In answering this, please consider **at least**: 
    - Are the parameter estimates reliable, unbiased estimates of the truth? Or, are they biased due to the way that the data is structured?
    - Are the uncertainty estimate reliable, unbiased estimates of sampling based variability? Or, are they biased due to the way that the data is structured? 

```{r Preliminary Model}

prelim_lm <- lm(total_fatalities_rate ~ year_of_observation + bac10 + bac08, data=data)

summary(prelim_lm)

std_residuals <- rstandard(prelim_lm)

# second option using binary year variables 
data[year_vars] <- lapply(data[year_vars], factor)
year_vars_minus_one <- year_vars[2:length(year_vars)]

fn_pm <- as.formula(paste('total_fatalities_rate ~', paste(year_vars_minus_one, collapse='+')))
mod_pm <- lm(fn_pm, data=data)

summary(mod_pm)
```


Fitting a linear model is a good place to start given its simplicity and comprehension to give first insights into the data. It also may immediately signal if ignoring cross sectional units has detrimentally effected the model. Here the model explains that year has a negative relationship with total fatality rate. Additionally, that establishing legality levels of BAC have negative effects on fatality rates as well. 

Driving did become safer over time as the trend in years clearly shows, but the BAC legality had a strong influence as well. At the beginning of the time period many states had no BAC limit, but as regulations changed thresholds were established. The model indicates these thresholds helped in the decrease in fatality rates.

The limitations of this model are that the different policy journeys of each state are mixed together in a potentially problematic way that fails to respect the true timing of state decisions to adjust policy and make driving safer. 

Additionally states could have started at very distinct levels of driving fatality rates that are obscured when data is pooled together. This is a leading reason that parameter estimates are not reliable and unbiased. The omitted variable of state not being considered leads to this. The influence of heteroscedasticity also gives evidence that the uncertainty estimates are not reliable and biased due to the data structure problems previously mentioned.

# (15 points) Expanded Model 

Expand the **Preliminary Model** by adding variables related to the following concepts: 

- Blood alcohol levels 
- Per se laws
- Primary seat belt laws (Note that if a law was enacted sometime within a year the fraction of the year is recorded in place of the zero-one indicator.)
- Secondary seat belt laws 
- Speed limits faster than 70 
- Graduated drivers licenses 
- Percent of the population between 14 and 24 years old
- Unemployment rate
- Vehicle miles driven per capita. 

If it is appropriate, include transformations of these variables. Please carefully explain carefully your rationale, which should be based on your EDA, behind any transformation you made. If no transformation is made, explain why transformation is not needed. 

- How are the blood alcohol variables defined? Interpret the coefficients that you estimate for this concept. 
- Do *per se laws* have a negative effect on the fatality rate? 
- Does having a primary seat belt law? 

```{r Expanded Model}
expand_lm <- lm(total_fatalities_rate ~ year_of_observation + graduated_drivers_license_law + bac10 + bac08 + primary_seatbelt_law + secondary_seatbelt_law + perse + unemployment_rate + perc14_24 + sl70plus + vehicmiles, data=data)

summary(expand_lm)

# second option using binary year variables and add scaling 
data$perc14_24 <- rescale(data$perc14_24)
data$unemployment_rate <- rescale(data$unemployment_rate)
data$vehicmilespc<- rescale(data$vehicmilespc)

cat_vars <- c("bac10", "bac08", "perse", "primary_seatbelt_law", "secondary_seatbelt_law", "sl70plus", "graduated_drivers_license_law") 
data[cat_vars] <- lapply(data[cat_vars], factor)

num_vars <- c("perc14_24", "unemployment_rate", "vehicmilespc")
combined_vars <- c(year_vars_minus_one, cat_vars, num_vars)

fn_exp <- as.formula(paste('total_fatalities_rate ~', paste(combined_vars, collapse='+')))
mod_exp <- lm(fn_exp, data=data)

summary(mod_exp)
```

Primary seat belt laws and Secondary seat belt laws are rounded to represent a Boolean flag and from our chart above should be considered separately due to the different levels of fatality rates. Graduated driver license and Per se laws were simlarly rounded to eliminate any data that may have not been a Boolean. Speed limit faster than 70 mph was kept as the original Boolean due to the EDA indicating a slight difference in the fatality rates associated. Unemployment Rate, Vehicle miles driven per capita, Percent of the population between 14 and 24 years old are also unaltered due to them being continuous variables. 

For Blood Alcohol levels the BAC 10% and BAC 8% law columns are considered separately to help us evaluate the relative impact in the model. The coefficient values are nearly identical at roughly -1.3. Meaning that the presence of a BAC law lowers fatalities by -1.2 per 100,000 people. Per Se laws have a slightly positive effect on fatalities however the coefficient is not significant and will be removed from the model. Having a primary seatbelt law has a significant and postive impact on fatalities showing the clearest evidence that a pooled linear model is not the appropriate approach to model the trends of the this panel data.

# (15 points) State-Level Fixed Effects 

Re-estimate the **Expanded Model** using fixed effects at the state level. 

- What do you estimate for coefficients on the blood alcohol variables? How do the coefficients on the blood alcohol variables change, if at all? 
- What do you estimate for coefficients on per se laws? How do the coefficients on per se laws change, if at all? 
- What do you estimate for coefficients on primary seat-belt laws? How do the coefficients on primary seatbelt laws change, if at all? 

Which set of estimates do you think is more reliable? Why do you think this? 

- What assumptions are needed in each of these models?  
- Are these assumptions reasonable in the current context?

```{r fixed effects model}
mod_fe <- plm(fn_exp, index="state", data=data, model="within")
summary(mod_fe)
```
The blood alcohol variables (`bac08` and `bac10`) both remain statistically significant in the fixed effects model at the state level. The coefficient for `bac08` dropped slightly from -2.19 to -1.18 and the coefficient for `bac10` also dropped from -1.24 to -0.87. The coefficients for the blood alcohol variables are negative and significant in both models. The interpretation is that when the bac08 law is in effect the traffic fatality rate is reduced by 1.18, whereas when the bac10 law is in effect the traffic fatality rate is only reduced by 0.87. This practically makes sense as we would expect a lower blood alcohol level to reduce the fatality rate. By controlling for any inherent fixed characteristics that vary across states, we that the magnitude of the effect of bac laws on fatality decreases, suggesting that there is a decent amount of variation in the characteristics from state to state. 

The statistical significance associated with `perse` increases in the fixed effects model and the coefficient increases in magnitude from -0.65 to -1.06, indicating that when the perse laws are in effect, controlling for fixed effects across states, the laws appear to be more effective at reducing the fatality rate.

The `primary_seatbelt_law` variable becomes significant in the fixed effects model. The coefficient also changes from -0.09 to -1.25 suggesting that when controlling for state level fixed effects, primary seat belt laws do reduce the traffic fatality rate. 

The fixed effects model produces a more reliable set of estimates because it relaxes the assumption of iid across data points. In the linear extended model, the assumption is that the data are iid, however due to the panel structure we know that there is dependency among observations. The fixed effects model accounts for this dependency by identifying that the data is linked by state. This model assumes that the data are iid within panels i.e., at the state level. This assumption is more reasonable than ignoring the panel structure of the data. It is reasonable to believe that there are fixed characteristics that vary across states i.e., no two states are identical. 

# (10 points) Consider a Random Effects Model 

Instead of estimating a fixed effects model, should you have estimated a random effects model?

- Please state the assumptions of a random effects model, and evaluate whether these assumptions are met in the data. 
- If the assumptions are, in fact, met in the data, then estimate a random effects model and interpret the coefficients of this model. Comment on how, if at all, the estimates from this model have changed compared to the fixed effects model. 
- If the assumptions are **not** met, then do not estimate the data. But, also comment on what the consequences would be if you were to *inappropriately* estimate a random effects model. Would your coefficient estimates be biased or not? Would your standard error estimates be biased or not? Or, would there be some other problem that might arise?

In this case, a random effects model assumes the state specific effects are uncorrelated with all the predictors in the model, which means there is no omitted variable bias from omitting fixed effects. We think this is a very strong assumption that are not met in our data. If we were to inappropriately estimate a random effects model, the coefficient estimates and standard error estimates will be biased, and will not be consistent. Only fixed effect model is the solely consistent model for this case.
  
# (10 points) Model Forecasts 

The COVID-19 pandemic dramatically changed patterns of driving. Find data (and include this data in your analysis, here) that includes some measure of vehicle miles driven in the US. Your data should at least cover the period from January 2018 to as current as possible. With this data, produce the following statements: 

```{r get data}
fredr_set_key("0ba6b0a40845d6abcf6b761a190609c7")
driving.df <- fredr(
  series_id = "M12MTVUSM227NFWA",
  observation_start = as.Date("2018-01-01")
) |>
  mutate(year = year(date)) |>
  mutate(month = month(date)) |>
  mutate(time_index = yearmonth(date)) |>
  select(c(time_index, year, month, value))
baseline_2018_driving <- driving.df |> 
  filter(year == 2018) |> 
  select(month, value) |>
  rename(baseline_month = month, baseline_value = value)
post_2018<-driving.df |> 
  filter(year != 2018) 
driving.change.ts <- post_2018 |>
  left_join(baseline_2018_driving, by = c('month' = 'baseline_month')) |>
  mutate(change = (value-baseline_value)) |>
  mutate(pct_change = (value-baseline_value)/baseline_value*100) |>
  select(time_index, pct_change) |>
  as_tsibble(index = time_index)
```

```{r data visuals}
driving.change.ts |>
  gg_subseries(pct_change) +
  labs(y = "Percentage Change from 2018 Total Driving", x = "Month",
       title = "US Total Vehicle Miles Traveled/Total Population 2018-2024")
driving.change.ts |> filter(pct_change == max(pct_change))
driving.change.ts |> filter(pct_change == min(pct_change))
```

- Comparing monthly miles driven in 2018 to the same months during the pandemic: 
  - What month demonstrated the largest decrease in driving? How much, in percentage terms, lower was this driving? 
    During the pandemic, February 2021 was the month that had experienced largest decrease in driving when compared to Feb 2018 with -11.95% decrease.
  - What month demonstrated the largest increase in driving? How much, in percentage terms, higher was this driving? 
    During the pandemic, February 2020 was the month that had experienced largest increase in driving when compared to Feb 2018 with 2.11% increase.
  
Now, use these changes in driving to make forecasts from your models. 

- Suppose that the number of miles driven per capita, increased by as much as the COVID boom. Using the FE estimates, what would the consequences be on the number of traffic fatalities? Please interpret the estimate.
Based on FE estimates, one unit change of miles driven per capita will have about 0.01% impact on the number of traffic fatalities. Therefore, about 2% increase in driving during February 2020 will estimate to have 0.0002% increase on the number of traffic fatalities.

- Suppose that the number of miles driven per capita, decreased by as much as the COVID bust. Using the FE estimates, what would the consequences be on the number of traffic fatalities? Please interpret the estimate.
Based on FE estimates, one unit change of miles driven per capita will have about 0.01% impact on the number of traffic fatalities. Therefore, about 12% decrease in driving during February 2021 will estimate to have 0.0012% decrease on the number of traffic fatalities.

# (5 points) Evaluate Error 

If there were serial correlation or heteroskedasticity in the idiosyncratic errors of the model, what would be the consequences on the estimators and their standard errors? Is there any serial correlation or heteroskedasticity? 
